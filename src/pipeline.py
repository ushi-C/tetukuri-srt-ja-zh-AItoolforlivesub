"""
ASR â†’ æ ¡å¯¹ â†’ ç¿»è¯‘ â†’ åŒè¯­ SRT è¾“å‡º
"""

import json
import re
import os
import gc
import shutil
import subprocess
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

import torch
from faster_whisper import WhisperModel
from rapidfuzz import fuzz
from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential
from tqdm import tqdm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…¨å±€é…ç½®
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WHISPER_MODEL_SIZE   = "large-v3"
LANGUAGE             = "ja"
TEMP_DIR             = "temp_clips"

MAX_WORKERS          = 4
RETRY_MAX_ATTEMPTS   = 3
MAX_CHARS_PER_CHUNK  = 3000
PROOFREAD_BATCH_SIZE = 100

TRANSLATE_SYSTEM_PROMPT = "æ‰§è¡Œå­—å¹•ç¿»è¯‘ä»»åŠ¡ï¼šå°†æ—¥è¯­ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚"
TRANSLATE_USER_TEMPLATE = (
    "è¯·é€è¡Œå°†æ—¥è¯­ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚æ ¹æ®ä¸Šä¸‹æ–‡è¯­å¢ƒçº æ­£çªå…€ä¹‹å¤„ï¼Œ"
    "äººåå’Œè‡ªé€ è¯ä¿ç•™æ—¥è¯­åŸæ–‡ï¼Œå¿…é¡»ä¸¥æ ¼ä¿æŒå¹¶è¾“å‡ºæ‰€æœ‰ IDã€‚\n"
    "æ ¼å¼ï¼š[ID] ä¸­æ–‡ç¿»è¯‘\n\n{input_block}"
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Token ç»Ÿè®¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TokenCounter:
    def __init__(self): self.total_tokens = 0
    def add(self, text: str): self.total_tokens += int(len(text) * 1.3)

usage_stats = TokenCounter()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å·¥å…·å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def time_to_seconds(t) -> float:
    if isinstance(t, (int, float)):
        return float(t)
    parts = str(t).strip().split(":")
    try:
        if len(parts) == 3: return int(parts[0])*3600 + int(parts[1])*60 + float(parts[2])
        if len(parts) == 2: return int(parts[0])*60 + float(parts[1])
        return float(parts[0])
    except Exception:
        return 0.0

def format_srt_time(seconds: float) -> str:
    ms       = int(abs(seconds % 1) * 1000)
    full_sec = int(abs(seconds))
    m, s = divmod(full_sec, 60)
    h, m = divmod(m, 60)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 1 Â· äººå·¥å¹²é¢„æ¨¡å¼ ASRï¼ˆåŸºäºå‚è€ƒ SRT æ—¶é—´è½´ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_srt_blocks(path: str) -> List[dict]:
    """è§£æ SRTï¼Œè¿”å› [{index, start, end, original_text}] åˆ—è¡¨ã€‚"""
    with open(path, "r", encoding="utf-8") as f:
        content = f.read()
    blocks = []
    time_pat = re.compile(r'(\d{2}:\d{2}:\d{2}[,.]\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}[,.]\d{3})')
    for block in re.split(r'\n\s*\n', content.strip()):
        lines = block.strip().split("\n")
        idx = next((i for i, l in enumerate(lines) if time_pat.search(l)), -1)
        if idx == -1: continue
        m = time_pat.search(lines[idx])
        blocks.append({
            "index":         len(blocks) + 1,
            "start":         m.group(1),
            "end":           m.group(2),
            "original_text": "\n".join(lines[idx+1:]).strip(),
        })
    return blocks

def _srt_ts_to_sec(t: str) -> float:
    t = t.replace(",", ".")
    h, m, s = t.split(":")
    return float(h)*3600 + float(m)*60 + float(s)

def _split_audio_block(audio_path: str, block: dict, idx: int) -> Optional[str]:
    start = _srt_ts_to_sec(block["start"])
    end   = _srt_ts_to_sec(block["end"])
    dur   = end - start
    if dur < 0.3: return None
    out = os.path.join(TEMP_DIR, f"clip_{idx:04d}.wav")
    cmd = ["ffmpeg","-y","-ss",str(start),"-i",audio_path,"-t",str(dur),
           "-ac","1","-ar","16000","-c:a","pcm_s16le","-avoid_negative_ts","make_zero",out]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
        if os.path.exists(out) and os.path.getsize(out) > 2048: return out
    except subprocess.CalledProcessError:
        pass
    return None

def _transcribe_clip(model: WhisperModel, clip_path: str) -> str:
    try:
        segs, _ = model.transcribe(clip_path, language=LANGUAGE, beam_size=5)
        return "".join(s.text for s in segs).strip()
    except Exception:
        return ""

def run_asr_from_srt(audio_path: str, srt_path: str) -> List[dict]:
    """
    ä»¥å‚è€ƒ SRT æ—¶é—´è½´ä¸ºåŸºå‡†ï¼Œé€æ®µåˆ‡ç‰‡åäº¤ç»™ Whisper è¯†åˆ«ã€‚
    è¿”å›: [{"start": float, "end": float, "text": str}, ...]
    """
    print("ğŸ§ [Step 1/4] æŒ‰ SRT æ—¶é—´è½´åˆ‡ç‰‡å¹¶ ASR è¯†åˆ«...")
    blocks = parse_srt_blocks(srt_path)
    print(f"   ğŸ“‹ å…± {len(blocks)} ä¸ªæ—¶é—´æ®µ")

    device       = "cuda" if torch.cuda.is_available() else "cpu"
    compute_type = "float16" if device == "cuda" else "int8"
    print(f"   ğŸ¤– åŠ è½½æ¨¡å‹ {WHISPER_MODEL_SIZE} ({device})")
    model = WhisperModel(WHISPER_MODEL_SIZE, device=device, compute_type=compute_type)

    os.makedirs(TEMP_DIR, exist_ok=True)
    result = []

    for i, block in enumerate(tqdm(blocks, desc="   è¯†åˆ«è¿›åº¦")):
        clip = _split_audio_block(audio_path, block, i)
        if clip:
            txt = _transcribe_clip(model, clip)
            try: os.remove(clip)
            except OSError: pass
        else:
            txt = ""
        result.append({
            "start": _srt_ts_to_sec(block["start"]),
            "end":   _srt_ts_to_sec(block["end"]),
            "text":  txt or block["original_text"],
        })

    shutil.rmtree(TEMP_DIR, ignore_errors=True)
    del model; gc.collect(); torch.cuda.empty_cache()
    print(f"   âœ… ASR å®Œæˆï¼Œå…± {len(result)} æ¡")
    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 2 Â· å¼¹å¹•æ¸…æ´—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_danmaku_cleaning(file_name: str) -> List[dict]:
    print("ğŸ§¹ [Step 2/4] æ¸…æ´—å‚è€ƒå¼¹å¹•...")
    buckets, clean_res = defaultdict(list), []
    KANJI = re.compile(r"[\u4E00-\u9FFF]")
    try:
        with open(file_name, "r", encoding="utf-8") as f:
            for line in f:
                data  = json.loads(line)
                items = data.get("replayChatItemAction", {}).get("actions", [])
                for a in items:
                    renderer = (a.get("addChatItemAction", {})
                                  .get("item", {})
                                  .get("liveChatTextMessageRenderer"))
                    if not renderer: continue
                    ts  = renderer.get("timestampText", {}).get("simpleText", "0:00")
                    msg = "".join(r.get("text","") for r in renderer.get("message",{}).get("runs",[]))
                    if len(msg) < 2 or not KANJI.search(msg): continue
                    key = (msg[0], len(msg)//2)
                    if any(fuzz.ratio(msg, old) >= 80 for old in buckets[key]): continue
                    buckets[key].append(msg)
                    clean_res.append({"_sec": time_to_seconds(ts), "text": msg})
    except Exception as e:
        print(f"   âš ï¸ å¼¹å¹•æ¸…æ´—å‡ºé”™: {e}")
    return sorted(clean_res, key=lambda x: x["_sec"])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 3 Â· æ™ºèƒ½æ ¡å¯¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_mapping(content: str) -> Dict[str, str]:
    mapping = {}
    for line in content.splitlines():
        m = re.search(r"(S\d+)", line)
        if m:
            sid       = m.group(1)
            text_part = re.split(r"S\d+[\s\]:ï¼š]*", line, maxsplit=1)[-1]
            mapping[sid] = text_part.strip()
    return mapping

@retry(stop=stop_after_attempt(RETRY_MAX_ATTEMPTS),
       wait=wait_exponential(multiplier=2, min=4, max=15))
def call_llm_api(client: OpenAI, messages: List[dict], temp: float = 0.2) -> str:
    usage_stats.add(str(messages))
    resp    = client.chat.completions.create(model=client._model, messages=messages, temperature=temp)
    content = resp.choices[0].message.content
    usage_stats.add(content)
    return content

def run_smart_proofread(client: OpenAI, asr_data: List[dict],
                        danmu_data: List[dict], bg_params: dict) -> List[dict]:
    print("ğŸ“¡ [Step 3/4] æ™ºèƒ½æ ¡å¯¹...")
    ctx     = f"Host: {bg_params['host_info']} | Title: {bg_params['stream_title']}"
    final   = []
    total   = len(asr_data)
    matched = 0

    for i in range(0, total, PROOFREAD_BATCH_SIZE):
        batch      = asr_data[i : i + PROOFREAD_BATCH_SIZE]
        w_s, w_e   = max(0, batch[0]["start"] - 15), batch[-1]["end"] + 15
        relevant   = [d for d in danmu_data if w_s <= d["_sec"] <= w_e]
        dm_in      = "\n".join(f"{d['_sec']:.1f}s: {d['text']}" for d in relevant)
        asr_in     = "\n".join(f"[S{i+idx+1:05d}] {s['text']}" for idx, s in enumerate(batch))
        messages   = [
            {"role": "system", "content": (
                f"æ‰§è¡Œæ—¥è¯­ ASR æ–‡æœ¬æ ¡å¯¹ä»»åŠ¡ã€‚æ ¡å¯¹èƒŒæ™¯ï¼š{ctx}ã€‚"
                "ä¾æ® [Host] ç¡®å®šè®²è¯äººèƒŒæ™¯ï¼Œä¾æ® [Title] ç¡®å®šè¯é¢˜èµ·å§‹èƒŒæ™¯ã€‚"
                "æ ¹æ®åŒæœŸå‚è€ƒå¼¹å¹•ä¿®æ­£ ASR ä¸­çš„é”™è¯¯ã€‚\n"
                "ã€çº¦æŸã€‘1.ä¿ç•™ [Sxxxxx] æ ‡ç­¾æ ¼å¼ã€‚2.æ— éœ€ä¿®æ”¹åˆ™åŸæ ·è¿”å›ã€‚3.ç¦æ­¢è¾“å‡ºè§£é‡Šã€‚")},
            {"role": "user", "content": f"[å‚è€ƒå¼¹å¹•]\n{dm_in}\n\n[å¾…æ ¡å¯¹ASR]\n{asr_in}"},
        ]
        try:
            mapping = extract_mapping(call_llm_api(client, messages))
            for idx, s in enumerate(batch):
                tid      = f"S{i+idx+1:05d}"
                res_text = mapping.get(tid, s["text"])
                if res_text != s["text"]: matched += 1
                final.append({"start": s["start"], "end": s["end"], "ja": res_text})
        except Exception:
            for s in batch: final.append({"start": s["start"], "end": s["end"], "ja": s["text"]})

    print(f"   âœ… æ ¡å¯¹å®Œæˆï¼Œè®¢æ­£ {matched} å¤„")
    return final


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Step 4 Â· å¹¶å‘ç¿»è¯‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _translate_worker(client: OpenAI, chunk: List[Tuple[str, str]], idx: int, total: int) -> Dict[str, str]:
    input_block = "\n".join([f"[{sid}] {txt}" for sid, txt in chunk])
    messages = [
        {"role": "system", "content": TRANSLATE_SYSTEM_PROMPT},
        {"role": "user", "content": TRANSLATE_USER_TEMPLATE.format(input_block=input_block)},
    ]
    try:
        content = call_llm_api(client, messages)
        mapping = extract_mapping(content)

        # æ£€æµ‹è§£æå¤±è´¥çš„ IDï¼Œé€æ¡å•ç‹¬é‡è¯•
        missing = [(sid, txt) for sid, txt in chunk if sid not in mapping]
        if missing:
            print(f"   âš ï¸ chunk {idx}/{total}: {len(missing)} æ¡è§£æå¤±è´¥ï¼Œé€æ¡é‡è¯•...")
            for sid, txt in missing:
                try:
                    single = call_llm_api(client, [
                        {"role": "system", "content": TRANSLATE_SYSTEM_PROMPT},
                        {"role": "user", "content": f"åªè¾“å‡ºä¸­æ–‡è¯‘æ–‡ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼š{txt}"},
                    ])
                    mapping[sid] = single.strip()
                except Exception:
                    mapping[sid] = txt  # ä¿ç•™æ—¥è¯­åŸæ–‡

        return mapping

    except Exception as e:
        print(f"   âŒ chunk {idx}/{total} æ•´ä½“å¤±è´¥: {e}ï¼Œä¿ç•™åŸæ–‡")
        return {sid: txt for sid, txt in chunk}  # æ•´ä½“å¤±è´¥æ—¶ä¿ç•™åŸæ–‡ï¼Œä¸è¿”å›ç©ºå­—å…¸


def run_parallel_translation(client: OpenAI, segments: List[dict]) -> List[dict]:
    print(f"ğŸš€ [Step 4/4] å¯åŠ¨å¹¶å‘ç¿»è¯‘ (å¹¶å‘: {MAX_WORKERS})...")
    items = [(f"S{i+1:05d}", s["ja"]) for i, s in enumerate(segments)]

    chunks, cur_chunk, cur_len = [], [], 0
    for sid, txt in items:
        line = f"[{sid}] {txt}"
        if cur_chunk and cur_len + len(line) > MAX_CHARS_PER_CHUNK:
            chunks.append(cur_chunk)
            cur_chunk, cur_len = [], 0
        cur_chunk.append((sid, txt))
        cur_len += len(line)
    if cur_chunk:
        chunks.append(cur_chunk)

    all_zh: Dict[str, str] = {}
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {
            executor.submit(_translate_worker, client, c, i + 1, len(chunks)): i
            for i, c in enumerate(chunks)
        }
        for f in as_completed(futures):
            all_zh.update(f.result())

    # ä»ç¼ºå¤±çš„ ID ç”¨æ—¥è¯­åŸæ–‡å¡«å……
    failed = 0
    for i, s in enumerate(segments):
        sid = f"S{i+1:05d}"
        s["zh"] = all_zh.get(sid) or s["ja"]
        if not all_zh.get(sid):
            failed += 1

    if failed:
        print(f"   âš ï¸ æœ€ç»ˆä»æœ‰ {failed} æ¡æœªç¿»è¯‘ï¼Œå·²ç”¨æ—¥è¯­åŸæ–‡å¡«å……")
    else:
        print("   âœ… å…¨éƒ¨ç¿»è¯‘å®Œæˆ")
    return segments


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SRT å†™å‡º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def write_bilingual_srt(final_data: List[dict], output_path: str) -> None:
    with open(output_path, "w", encoding="utf-8") as f:
        for i, s in enumerate(final_data, 1):
            f.write(f"{i}\n{format_srt_time(s['start'])} --> {format_srt_time(s['end'])}\n"
                    f"{s['ja']}\n{s['zh']}\n\n")
    print(f"   ğŸ’¾ å·²è¾“å‡ºï¼š{output_path}")
